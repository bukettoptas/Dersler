# ğŸ“ Makine Ã–ÄŸrenmesi Model DoÄŸrulama

> **Makine Ã–ÄŸrenmesinde Model DoÄŸrulama Teknikleri**
> 
> *HazÄ±rlayan: Dr. Buket ToptaÅŸ*  
> *Tarih: 2025*

### Online Demo
HiÃ§bir kurulum gerektirmez! DoÄŸrudan ÅŸu linkten eriÅŸin:

ğŸ‘‰ [Model DoÄŸrulama]
(https://bukettoptas.github.io/Dersler/makine_ogrenmesi/validation/validation.html)

## ğŸ¯ GiriÅŸ
#### **Model DoÄŸrulama** - Modelin BaÅŸarÄ±sÄ±nÄ± NasÄ±l Ã–lÃ§eriz?
Bir makine Ã¶ÄŸrenmesi modelinin ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamak iÃ§in Ã§eÅŸitli metrikler kullanÄ±lÄ±r. **Confusion Matrix** (KarmaÅŸÄ±klÄ±k Matrisi), modelin doÄŸru ve yanlÄ±ÅŸ tahminlerini gÃ¶rselleÅŸtirir:
- **True Positives (TP)**: DoÄŸru pozitif tahminler
- **False Positives (FP)**: YanlÄ±ÅŸ pozitif tahminler (Tip I Hata)
- **False Negatives (FN)**: YanlÄ±ÅŸ negatif tahminler (Tip II Hata)
- **True Negatives (TN)**: DoÄŸru negatif tahminler


#### **EÄŸitim-Test AyrÄ±mÄ±** - Veriyi DoÄŸru BÃ¶lmek Neden Ã–nemli?
Makine Ã¶ÄŸrenmesinde "data leakage" (veri sÄ±zmasÄ±) en yaygÄ±n hatalardan biridir. Veri seti Ã¼Ã§ parÃ§aya ayrÄ±lmalÄ±dÄ±r:
- **EÄŸitim Seti (%60-80)**: Modelin parametrelerini Ã¶ÄŸrenmesi iÃ§in
- **DoÄŸrulama Seti (%10-20)**: Hiperparametre optimizasyonu ve model seÃ§imi iÃ§in
- **Test Seti (%10-20)**: Final performans deÄŸerlendirmesi iÃ§in


#### **Ã‡apraz DoÄŸrulama (K-Fold)** - Daha GÃ¼venilir Performans Tahmini
KÃ¼Ã§Ã¼k veri setlerinde tek bir train-test split'i yanÄ±ltÄ±cÄ± olabilir. **K-Fold Cross-Validation**, veriyi K parÃ§aya bÃ¶ler ve her parÃ§ayÄ± sÄ±rayla test seti olarak kullanÄ±r. Bu sayede:
- TÃ¼m veri hem eÄŸitim hem test iÃ§in kullanÄ±lÄ±r
- Performans tahmini daha kararlÄ± olur
- Model varyansÄ± azalÄ±r


#### **RegÃ¼larizasyon** - Overfitting'i NasÄ±l Ã–nleriz?
Model Ã§ok karmaÅŸÄ±k olduÄŸunda eÄŸitim verisini "ezberlemeye" baÅŸlar (overfitting). RegÃ¼larizasyon, model aÄŸÄ±rlÄ±klarÄ±na ceza ekleyerek bunu Ã¶nler:

**L1 RegÃ¼larizasyon (Lasso)**: `Cost = MSE + Î» Ã— Î£|wi|`
- BazÄ± aÄŸÄ±rlÄ±klarÄ± tam sÄ±fÄ±ra iter
- Otomatik Ã¶zellik seÃ§imi yapar
- Seyrek (sparse) modeller oluÅŸturur

**L2 RegÃ¼larizasyon (Ridge)**: `Cost = MSE + Î» Ã— Î£(wiÂ²)`
- TÃ¼m aÄŸÄ±rlÄ±klarÄ± kÃ¼Ã§Ã¼ltÃ¼r ama sÄ±fÄ±rlamaz
- Korelasyonlu Ã¶zelliklerle iyi baÅŸa Ã§Ä±kar
- Daha stabil modeldir


#### **Gradyan Ä°niÅŸ** - Optimizasyon NasÄ±l Ã‡alÄ±ÅŸÄ±r?
Gradyan iniÅŸ, maliyet fonksiyonunu minimize etmek iÃ§in kullanÄ±lan temel optimizasyon algoritmasÄ±dÄ±r:

**FormÃ¼l**: `Î¸(t+1) = Î¸(t) - Î± Ã— âˆ‡J(Î¸(t))`

**Learning Rate (Î±)** en kritik hiperparametredir:
- **Ã‡ok kÃ¼Ã§Ã¼k**: YavaÅŸ yakÄ±nsama, uzun eÄŸitim sÃ¼resi
- **Ã‡ok bÃ¼yÃ¼k**: Divergence (sapma), minimum'a ulaÅŸamama
- **Optimal**: HÄ±zlÄ± ve stabil yakÄ±nsama


#### **Erken Durdurma (Early Stopping)** - EÄŸitimi Ne Zaman DurduralÄ±m?
Model eÄŸitilirken validation loss bir noktadan sonra artmaya baÅŸlar - bu overfitting'in iÅŸaretidir. Early stopping, bu noktayÄ± tespit eder ve eÄŸitimi otomatik durdurur:

**MantÄ±k**:
- Her epoch'ta validation loss kontrol edilir
- GeliÅŸme olmazsa "patience counter" artÄ±rÄ±lÄ±r
- Counter >= patience olduÄŸunda eÄŸitim durur
- En iyi modelin aÄŸÄ±rlÄ±klarÄ± geri yÃ¼klenir


#### **Rastgele Orman (Random Forest)** - Topluluk GÃ¼cÃ¼
Random Forest, birden fazla karar aÄŸacÄ±nÄ± birleÅŸtirerek gÃ¼Ã§lÃ¼ tahminler yapar. ÃœÃ§ temel prensip Ã¼zerine kuruludur:

**1. Bagging (Bootstrap Aggregating)**
- Her aÄŸaÃ§, veri setinden yerine koyarak (with replacement) rastgele Ã¶rnekler gÃ¶rÃ¼r
- Tipik olarak verinin ~63%'Ã¼ her aÄŸaÃ§ iÃ§in kullanÄ±lÄ±r

**2. Feature Randomness**
- Her dÃ¼ÄŸÃ¼mde tÃ¼m Ã¶zellikler yerine rastgele bir alt kÃ¼me kullanÄ±lÄ±r
- SÄ±nÄ±flandÄ±rma: âˆšp Ã¶zellik
- Regresyon: p/3 Ã¶zellik

**3. Voting/Averaging**
- SÄ±nÄ±flandÄ±rma: Ã‡oÄŸunluk oyu (majority voting)
- Regresyon: Ortalama (averaging)


## ğŸ’» KullanÄ±m

### Online Demo
HiÃ§bir kurulum gerektirmez! DoÄŸrudan ÅŸu linkten eriÅŸin:

ğŸ‘‰ **[Demo'yu AÃ§](https://bukettoptas.github.io/Dersler/makine_ogrenmesi/validation/validation.html)** 

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! 

### NasÄ±l KatkÄ±da Bulunabilirsiniz?

1. **Fork** yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b yeni-ozellik`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -am 'Yeni Ã¶zellik eklendi'`)
4. Branch'inizi push edin (`git push origin yeni-ozellik`)
5. **Pull Request** oluÅŸturun

---

## ğŸ› Sorun Bildirme

Bir hata buldunuz mu? [Issue aÃ§Ä±n](https://github.com/bukettoptas/Dersler/makine_ogrenmesi/issues)

---

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

**[AdÄ±nÄ±z]**
- GitHub: [@bukettoptas](https://github.com/bukettoptas)
- LinkedIn: [buket-toptaÅŸ-142b6677](https://www.linkedin.com/in/buket-topta%C5%9F-142b6677/)
- Email: buketecrinozturk@gmail.com

---

## ğŸ™ TeÅŸekkÃ¼rler

- Makine Ã¶ÄŸrenmesi topluluÄŸuna
- AÃ§Ä±k kaynak katkÄ±cÄ±lara
- Geri bildirim saÄŸlayan herkese

---
<div align="center">

### â­ Projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n! â­

**Made with â¤ï¸ for ML learners**

</div>
